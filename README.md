# Titanic LightGBM Prediction

Kaggle Titanicãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ãŸLightGBMç”Ÿå­˜äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã€‚
**CLIï¼ˆã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ï¼‰ã¨Jupyter Notebookã®ä¸¡æ–¹ã«å¯¾å¿œã€‚**

## ğŸš€ Features

- **2ã¤ã®ä½¿ç”¨æ–¹æ³•**: CLIï¼ˆmain.pyï¼‰ã¨Jupyter Notebookï¼ˆç‹¬ç«‹é–¢æ•°ï¼‰ã®ä¸¡å¯¾å¿œ
- **ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç‹¬ç«‹æ€§**: å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯å®Œå…¨ã«ç‹¬ç«‹ã—ã€Jupyter Notebookã§ã‚³ãƒ”ãƒšå®Ÿè¡Œå¯èƒ½
- **ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…**: LightGBMã®ãƒã‚¤ãƒ†ã‚£ãƒ–æ©Ÿèƒ½ã‚’æ´»ç”¨ã—ã€æ¬ æå€¤è£œå®Œãƒ»ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä¸è¦
- **K-Fold CV**: 5åˆ†å‰²äº¤å·®æ¤œè¨¼ã«ã‚ˆã‚‹ç²¾åº¦è©•ä¾¡
- **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–**: Optunaã«ã‚ˆã‚‹è‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
- **å¯è¦–åŒ–**: å­¦ç¿’æ›²ç·šã€ç‰¹å¾´é‡é‡è¦åº¦ã€éƒ¨åˆ†ä¾å­˜ãƒ—ãƒ­ãƒƒãƒˆã‚’è‡ªå‹•ç”Ÿæˆ
- **Dockerå¯¾å¿œ**: ç’°å¢ƒæ§‹ç¯‰ä¸è¦ã§å®Ÿè¡Œå¯èƒ½

## ğŸ“Š Performance

- **CV Accuracy**: 83.39% Â± 0.21% (2-Fold), 84.06% Â± 2.01% (5-Fold with optimization)
- **Expected Kaggle Score**: 0.76-0.78 (Public LB)

---

## ğŸ¯ Quick Start

### æ–¹æ³•1: Jupyter Notebookï¼ˆæ¨å¥¨ï¼‰

å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç‹¬ç«‹ã—ã¦å®Ÿè¡Œã§ãã€ã‚»ãƒ«å˜ä½ã§å®Ÿé¨“å¯èƒ½ã§ã™ã€‚

```python
# Cell 1: ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
import sys
sys.path.insert(0, 'src')

# Cell 2: ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
from preprocessor import preprocess_data

result = preprocess_data(
    train_path='data/train.csv',
    test_path='data/test.csv',
    target_col='Survived',
    id_col='PassengerId',
    drop_cols=['Name', 'Ticket', 'Cabin'],
    categorical_cols=['Sex', 'Embarked']
)

# Cell 3: ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
from train import train_model

train_result = train_model(
    train_data_path='processed_data/processed_train.csv',
    target_col='Survived',
    id_col='PassengerId',
    categorical_cols=['Sex', 'Embarked'],
    generate_plots=True
)
print(f"Mean accuracy: {train_result['mean_accuracy']:.4f}")

# Cell 4: äºˆæ¸¬
from predict import predict

submission = predict(
    test_data_path='processed_data/processed_test.csv',
    model_path='models/lightgbm_model.txt',
    id_col='PassengerId',
    target_col='Survived',
    categorical_cols=['Sex', 'Embarked']
)
print(submission.head())
```

ğŸ“ **è©³ç´°**: `jupyter_example.py` ã«å®Œå…¨ãªä½¿ç”¨ä¾‹ã‚’è¨˜è¼‰

### æ–¹æ³•2: CLIï¼ˆã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ï¼‰

å¾“æ¥é€šã‚Šã®ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚‚å¯èƒ½ã§ã™ã€‚

```bash
# 1. æ¨™æº–è¨“ç·´ï¼ˆå›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ç´„10ç§’ï¼‰
python main.py train --train-data data/train.csv --test-data data/test.csv \
  --target-col Survived --id-col PassengerId \
  --drop-cols Name Ticket Cabin --categorical-cols Sex Embarked

# 2. Optunaã«ã‚ˆã‚‹æœ€é©åŒ–ï¼ˆç´„10-20åˆ†ã€æ¨å¥¨ï¼‰
python main.py optimize --train-data data/train.csv --test-data data/test.csv \
  --target-col Survived --id-col PassengerId \
  --drop-cols Name Ticket Cabin --categorical-cols Sex Embarked

# 3. äºˆæ¸¬ç”Ÿæˆ
python main.py predict --train-data data/train.csv --test-data data/test.csv \
  --target-col Survived --id-col PassengerId \
  --drop-cols Name Ticket Cabin --categorical-cols Sex Embarked

# 4. å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œï¼ˆtrain â†’ predictï¼‰
python main.py all --train-data data/train.csv --test-data data/test.csv \
  --target-col Survived --id-col PassengerId \
  --drop-cols Name Ticket Cabin --categorical-cols Sex Embarked
```

---

## ğŸ“ Project Structure

```
project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv                      # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ï¼ˆKaggleæä¾›ï¼‰
â”‚   â””â”€â”€ test.csv                       # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆKaggleæä¾›ï¼‰
â”‚
â”œâ”€â”€ processed_data/                    # å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ï¼ˆJupyterä½¿ç”¨æ™‚ï¼‰
â”‚   â”œâ”€â”€ processed_train.csv            # ç‰¹å¾´é‡ + ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ + ID
â”‚   â”œâ”€â”€ processed_test.csv             # ç‰¹å¾´é‡ + ID
â”‚   â””â”€â”€ metadata.json                  # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ—ç­‰ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ lightgbm_model.txt             # train()ã‹ã‚‰ç”Ÿæˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ï¼‰
â”‚   â”œâ”€â”€ lightgbm_model.pkl             # optimize()ã‹ã‚‰ç”Ÿæˆï¼ˆpickleå½¢å¼ï¼‰
â”‚   â”œâ”€â”€ lightgbm_params.json           # ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ + CVçµæœ
â”‚   â””â”€â”€ optuna_study.pkl               # Optunaã‚¹ã‚¿ãƒ‡ã‚£ï¼ˆåˆ†æç”¨ï¼‰
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ submission.csv                 # Kaggleæå‡ºç”¨ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”œâ”€â”€ learning_curves.png            # å­¦ç¿’æ›²ç·šï¼ˆè¨“ç·´/æ¤œè¨¼æå¤±ï¼‰
â”‚   â”œâ”€â”€ feature_importance.png         # ç‰¹å¾´é‡é‡è¦åº¦
â”‚   â””â”€â”€ partial_dependence_plots.png   # éƒ¨åˆ†ä¾å­˜ãƒ—ãƒ­ãƒƒãƒˆ
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                      # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šï¼ˆCLIç”¨ï¼‰
â”‚   â”œâ”€â”€ preprocessor.py                # å‰å‡¦ç†
â”‚   â”‚   â”œâ”€â”€ preprocess_data()          # ğŸ†• Jupyterç”¨ç‹¬ç«‹é–¢æ•°
â”‚   â”‚   â””â”€â”€ load_metadata()            # ğŸ†• ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­è¾¼
â”‚   â”œâ”€â”€ train.py                       # è¨“ç·´
â”‚   â”‚   â””â”€â”€ train_model()              # ğŸ†• Jupyterç”¨ç‹¬ç«‹é–¢æ•°
â”‚   â”œâ”€â”€ optimize.py                    # Optunaæœ€é©åŒ–
â”‚   â”‚   â””â”€â”€ optimize_hyperparameters() # ğŸ†• Jupyterç”¨ç‹¬ç«‹é–¢æ•°
â”‚   â””â”€â”€ predict.py                     # äºˆæ¸¬
â”‚       â””â”€â”€ predict()                  # ğŸ†• Jupyterç”¨ç‹¬ç«‹é–¢æ•°
â”‚
â”œâ”€â”€ main.py                            # CLIã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”œâ”€â”€ jupyter_example.py                 # ğŸ†• Jupyterä½¿ç”¨ä¾‹
â”œâ”€â”€ test_jupyter_functions.py          # ğŸ†• ç‹¬ç«‹é–¢æ•°ã®ãƒ†ã‚¹ãƒˆ
â”‚
â”œâ”€â”€ Dockerfile                         # Dockerè¨­å®š
â”œâ”€â”€ docker-compose.yml                 # Docker Composeè¨­å®š
â”œâ”€â”€ requirements.txt                   # ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
â””â”€â”€ README.md                          # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
```

---

## ğŸ”§ Installation

### ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ

```bash
# ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt
```

### Docker

```bash
# ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰
docker build -t titanic-lightgbm .

# å­¦ç¿’å®Ÿè¡Œ
docker run --rm \
  -v "$(pwd)/data:/app/data" \
  -v "$(pwd)/models:/app/models" \
  -v "$(pwd)/output:/app/output" \
  titanic-lightgbm python main.py train

# äºˆæ¸¬å®Ÿè¡Œ
docker run --rm \
  -v "$(pwd)/data:/app/data" \
  -v "$(pwd)/models:/app/models" \
  -v "$(pwd)/output:/app/output" \
  titanic-lightgbm python main.py predict
```

### Docker Compose

```bash
# ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•
docker-compose up -d

# ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ä½œæ¥­
docker-compose exec titanic bash

# ã‚³ãƒ³ãƒ†ãƒŠå†…ã§å®Ÿè¡Œ
python main.py train
python main.py predict

# ã‚³ãƒ³ãƒ†ãƒŠåœæ­¢
docker-compose down
```

---

## ğŸ“– Usage Details

### Jupyter Notebookç”¨ã®ç‹¬ç«‹é–¢æ•°

å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ `src.*` ã¸ã®ä¾å­˜ãªã—ã§å®Œå…¨ã«ç‹¬ç«‹ã—ã¦ã„ã¾ã™ã€‚

#### 1. preprocess_data() - ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†

```python
from preprocessor import preprocess_data, load_metadata

result = preprocess_data(
    train_path='data/train.csv',
    test_path='data/test.csv',
    target_col='Survived',
    id_col='PassengerId',
    drop_cols=['Name', 'Ticket', 'Cabin'],
    categorical_cols=['Sex', 'Embarked'],
    output_dir='processed_data'
)

# æˆ»ã‚Šå€¤
# {
#     'train_output': 'processed_data/processed_train.csv',
#     'test_output': 'processed_data/processed_test.csv',
#     'metadata': 'processed_data/metadata.json'
# }

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆå¾Œã§ä½¿ç”¨ã™ã‚‹å ´åˆï¼‰
metadata = load_metadata('processed_data/metadata.json')
```

**å‡ºåŠ›:**
- `processed_train.csv`: ç‰¹å¾´é‡ + ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ + ID
- `processed_test.csv`: ç‰¹å¾´é‡ + ID
- `metadata.json`: ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ—ç­‰ã®ãƒ¡ã‚¿æƒ…å ±

#### 2. train_model() - ãƒ¢ãƒ‡ãƒ«è¨“ç·´

```python
from train import train_model

result = train_model(
    train_data_path='processed_data/processed_train.csv',
    target_col='Survived',
    id_col='PassengerId',
    categorical_cols=['Sex', 'Embarked'],
    params=None,                   # Noneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    num_boost_round=1000,
    early_stopping_rounds=50,
    n_folds=5,
    generate_plots=True,           # ã‚°ãƒ©ãƒ•ç”Ÿæˆã®ON/OFF
    model_output_dir='models',
    plots_output_dir='output'
)

# æˆ»ã‚Šå€¤
# {
#     'model_path': 'models/lightgbm_model.txt',
#     'cv_scores': [0.8318, 0.8360, ...],
#     'mean_accuracy': 0.8339,
#     'std_accuracy': 0.0021,
#     'feature_importance': DataFrame
# }
```

**å‡ºåŠ›:**
- `models/lightgbm_model.txt`: è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
- `output/learning_curves.png`: å­¦ç¿’æ›²ç·šï¼ˆgenerate_plots=Trueæ™‚ï¼‰
- `output/feature_importance.png`: ç‰¹å¾´é‡é‡è¦åº¦
- `output/partial_dependence_plots.png`: éƒ¨åˆ†ä¾å­˜ãƒ—ãƒ­ãƒƒãƒˆ

#### 3. optimize_hyperparameters() - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–

```python
from optimize import optimize_hyperparameters

result = optimize_hyperparameters(
    train_data_path='processed_data/processed_train.csv',
    target_col='Survived',
    id_col='PassengerId',
    categorical_cols=['Sex', 'Embarked'],
    n_trials=100,                  # Optunaè©¦è¡Œå›æ•°
    n_folds=5,
    model_output_dir='models'
)

# æˆ»ã‚Šå€¤
# {
#     'model_path': 'models/lightgbm_model.pkl',
#     'params_path': 'models/lightgbm_params.json',
#     'study_path': 'models/optuna_study.pkl',
#     'best_params': {...},
#     'best_score': 0.8406
# }
```

**å‡ºåŠ›:**
- `models/lightgbm_model.pkl`: æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«
- `models/lightgbm_params.json`: ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ + CVçµæœ
- `models/optuna_study.pkl`: Optunaã‚¹ã‚¿ãƒ‡ã‚£ï¼ˆåˆ†æç”¨ï¼‰

#### 4. predict() - äºˆæ¸¬ç”Ÿæˆ

```python
from predict import predict

submission = predict(
    test_data_path='processed_data/processed_test.csv',
    model_path='models/lightgbm_model.txt',  # ã¾ãŸã¯ .pkl
    id_col='PassengerId',
    target_col='Survived',
    categorical_cols=['Sex', 'Embarked'],
    output_path='output/submission.csv'
)

# æˆ»ã‚Šå€¤: DataFrameãŒè¿”ã•ã‚Œã‚‹
#    PassengerId  Survived
# 0          892         0
# 1          893         0
# ...
```

**å‡ºåŠ›:**
- `output/submission.csv`: Kaggleæå‡ºç”¨ãƒ•ã‚¡ã‚¤ãƒ«

### CLIç”¨ã‚³ãƒãƒ³ãƒ‰ä¸€è¦§

```bash
# æ¨™æº–è¨“ç·´ï¼ˆå›ºå®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
python main.py train --train-data <PATH> --test-data <PATH> \
  --target-col <COL> --id-col <COL> \
  --drop-cols <COL1> <COL2> ... \
  --categorical-cols <COL1> <COL2> ...

# Optunaæœ€é©åŒ–
python main.py optimize --train-data <PATH> --test-data <PATH> \
  --target-col <COL> --id-col <COL> \
  --drop-cols <COL1> <COL2> ... \
  --categorical-cols <COL1> <COL2> ... \
  --n-trials 100

# äºˆæ¸¬ç”Ÿæˆ
python main.py predict --train-data <PATH> --test-data <PATH> \
  --target-col <COL> --id-col <COL> \
  --drop-cols <COL1> <COL2> ... \
  --categorical-cols <COL1> <COL2> ...

# å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆtrain â†’ predictï¼‰
python main.py all --train-data <PATH> --test-data <PATH> \
  --target-col <COL> --id-col <COL> \
  --drop-cols <COL1> <COL2> ... \
  --categorical-cols <COL1> <COL2> ...
```

---

## ğŸ§ª Implementation Details

### ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†

- **å‰Šé™¤åˆ—**: PassengerIdï¼ˆå­¦ç¿’æ™‚ï¼‰, Name, Ticket, Cabin
- **ä½¿ç”¨ç‰¹å¾´é‡**: Pclass, Sex, Age, SibSp, Parch, Fare, Embarkedï¼ˆ7åˆ—ï¼‰
- **ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°**: Sex, Embarkedï¼ˆcategoryå‹ã«å¤‰æ›ã€LightGBMãŒè‡ªå‹•å‡¦ç†ï¼‰
- **æ¬ æå€¤å‡¦ç†**: Ageã€Embarkedã€Fareã®æ¬ æå€¤ã¯LightGBMãŒè‡ªå‹•å‡¦ç†ï¼ˆè£œå®Œä¸è¦ï¼‰
- **ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°**: LightGBMã®ãƒã‚¤ãƒ†ã‚£ãƒ–ãªã‚«ãƒ†ã‚´ãƒªå‡¦ç†æ©Ÿèƒ½ã‚’ä½¿ç”¨ï¼ˆOne-hotä¸è¦ï¼‰

### ãƒ¢ãƒ‡ãƒ«è¨­å®š

- **ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **: LightGBM (Gradient Boosting Decision Tree)
- **ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
  - `objective`: binaryï¼ˆ2å€¤åˆ†é¡ï¼‰
  - `metric`: binary_logloss
  - `boosting_type`: gbdt
  - `learning_rate`: 0.05
  - `num_leaves`: 31
  - `feature_fraction`: 0.9
  - `random_state`: 42
- **Early Stopping**: 50ãƒ©ã‚¦ãƒ³ãƒ‰
- **äº¤å·®æ¤œè¨¼**: Stratified 5-Fold CV

### ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼ˆOptunaï¼‰

- **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: Optuna v3.5.0
- **æ¢ç´¢ç©ºé–“**:
  - `num_leaves`: [15, 63]
  - `learning_rate`: [0.01, 0.1]ï¼ˆlog scaleï¼‰
  - `feature_fraction`: [0.6, 1.0]
  - `bagging_fraction`: [0.6, 1.0]
  - `bagging_freq`: [1, 7]
  - `min_child_samples`: [5, 50]
  - `lambda_l1`: [0.0, 10.0]ï¼ˆL1æ­£å‰‡åŒ–ï¼‰
  - `lambda_l2`: [0.0, 10.0]ï¼ˆL2æ­£å‰‡åŒ–ï¼‰
- **è©¦è¡Œå›æ•°**: 100ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
- **ã‚µãƒ³ãƒ—ãƒ©ãƒ¼**: TPE (Tree-structured Parzen Estimator)
- **ãƒ—ãƒ«ãƒ¼ãƒŠãƒ¼**: MedianPrunerï¼ˆæ—©æœŸæ‰“ã¡åˆ‡ã‚Šï¼‰
- **ç›®çš„é–¢æ•°**: 5-Fold CVã®å¹³å‡ç²¾åº¦ã‚’æœ€å¤§åŒ–

### ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆè¨“ç·´çµæœã®ä¾‹ï¼‰

| Feature | Importance (Gain) |
|---------|-------------------|
| Sex     | 2718              |
| Fare    | 1240              |
| Age     | 1229              |
| Pclass  | 905               |
| SibSp   | 148               |
| Embarked| 127               |
| Parch   | 90                |

---

## ğŸ“Š Output Files

### models/lightgbm_model.txt
`train_model()` ã‹ã‚‰ç”Ÿæˆã•ã‚Œã‚‹è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ï¼‰

### models/lightgbm_model.pkl
`optimize_hyperparameters()` ã‹ã‚‰ç”Ÿæˆã•ã‚Œã‚‹æœ€é©åŒ–æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆpickleå½¢å¼ï¼‰

### models/lightgbm_params.json
ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨CVçµæœ:
```json
{
  "best_params": {...},
  "cv_results": {
    "mean_accuracy": 0.8406,
    "std_accuracy": 0.0201,
    "fold_scores": [0.8318, 0.8360, ...]
  },
  "best_iteration": 156,
  "optuna_study": {...},
  "timestamp": "2026-01-12T20:20:00"
}
```

### processed_data/metadata.json
å‰å‡¦ç†ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿:
```json
{
  "categorical_cols": ["Sex", "Embarked"],
  "feature_names": ["Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked"],
  "target_col": "Survived",
  "id_col": "PassengerId",
  "drop_cols": ["Name", "Ticket", "Cabin"]
}
```

### output/submission.csv
Kaggleæå‡ºç”¨ãƒ•ã‚¡ã‚¤ãƒ«:
```csv
PassengerId,Survived
892,0
893,0
894,0
...
```

### å¯è¦–åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆgenerate_plots=Trueæ™‚ï¼‰

- **learning_curves.png**: è¨“ç·´/æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®æå¤±æ¨ç§»ï¼ˆ5-Foldå¹³å‡ï¼‰
- **feature_importance.png**: ç‰¹å¾´é‡ã®é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
- **partial_dependence_plots.png**: å„ç‰¹å¾´é‡ã®éƒ¨åˆ†ä¾å­˜ï¼ˆ3x3ã‚°ãƒªãƒƒãƒ‰ï¼‰

---

## ğŸ”„ Workflow Comparison

### ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼1: æ¨™æº–è¨“ç·´ï¼ˆtrainï¼‰

**CLI:**
```bash
python main.py train
python main.py predict
```

**Jupyter:**
```python
from train import train_model
result = train_model(...)
```

- **ç”¨é€”**: ç´ æ—©ã„ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã€ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ä½œæˆ
- **å‡ºåŠ›**: `models/lightgbm_model.txt`
- **æ‰€è¦æ™‚é–“**: ç´„5-10ç§’

### ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼2: æœ€é©åŒ–è¨“ç·´ï¼ˆoptimizeï¼‰

**CLI:**
```bash
python main.py optimize --n-trials 100
python main.py predict
```

**Jupyter:**
```python
from optimize import optimize_hyperparameters
result = optimize_hyperparameters(n_trials=100)
```

- **ç”¨é€”**: Kaggleæå‡ºç”¨ã®æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«
- **å‡ºåŠ›**: `models/lightgbm_model.pkl`, `lightgbm_params.json`, `optuna_study.pkl`
- **æ‰€è¦æ™‚é–“**: ç´„10-20åˆ†

---

## ğŸ§‘â€ğŸ’» Development

### ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ

```bash
# ç‹¬ç«‹é–¢æ•°ã®ãƒ†ã‚¹ãƒˆ
python test_jupyter_functions.py
```

### æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®é©ç”¨

Jupyter Notebookç”¨ã®é–¢æ•°ã¯å®Œå…¨ã«æ±ç”¨çš„ã§ã€ä»»æ„ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é©ç”¨å¯èƒ½:

```python
# ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¾‹
result = preprocess_data(
    train_path='data/custom_train.csv',
    test_path='data/custom_test.csv',
    target_col='Churn',                    # è‡ªç”±ã«å¤‰æ›´å¯èƒ½
    id_col='CustomerId',
    drop_cols=['Name', 'Email'],
    categorical_cols=['Gender', 'Country']
)

train_result = train_model(
    train_data_path='processed_data/processed_train.csv',
    target_col='Churn',
    id_col='CustomerId',
    categorical_cols=['Gender', 'Country']
)
```

---

## ğŸ“¦ Requirements

### Pythonç’°å¢ƒ

- Python 3.11+
- pandas 2.1.4
- numpy 1.26.2
- scikit-learn 1.3.2
- lightgbm 4.1.0
- optuna 3.5.0
- joblib 1.3.2
- matplotlib 3.x
- seaborn 0.x

### Dockerç’°å¢ƒ

- Docker 20.10+
- Docker Compose 1.29+

ã™ã¹ã¦ã®ä¾å­˜é–¢ä¿‚ã¯ `requirements.txt` ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚

---

## ğŸ“ Key Innovations

### 1. ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç‹¬ç«‹æ€§
å„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æ–°é–¢æ•°ï¼ˆ`preprocess_data()`, `train_model()`, `optimize_hyperparameters()`, `predict()`ï¼‰ã¯å®Œå…¨ã«ç‹¬ç«‹ã—ã¦ãŠã‚Šã€`src.*` ã‹ã‚‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¯ä¸è¦ã§ã™ã€‚

### 2. CSVçµŒç”±ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼
ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ã¯ä¸­é–“CSVãƒ•ã‚¡ã‚¤ãƒ«ã§æ¥ç¶šã•ã‚Œã€å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç‹¬ç«‹ã—ã¦å®Ÿè¡Œãƒ»æ¤œè¨¼ã§ãã¾ã™ã€‚

### 3. æŸ”è»Ÿãªå®Ÿè¡Œæ–¹æ³•
åŒã˜ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§CLIï¼ˆè‡ªå‹•åŒ–å‘ãï¼‰ã¨Jupyterï¼ˆå®Ÿé¨“å‘ãï¼‰ã®ä¸¡æ–¹ã«å¯¾å¿œã€‚

### 4. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†
`metadata.json` ã§ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«åˆ—ç­‰ã®æƒ…å ±ã‚’ä¿å­˜ã—ã€å†ç¾æ€§ã‚’ç¢ºä¿ã€‚

---

## ğŸ“ License

MIT License

---

## ğŸ™ Acknowledgments

- [Kaggle Titanic Competition](https://www.kaggle.com/c/titanic)
- [LightGBM](https://github.com/microsoft/LightGBM)
- [Optuna](https://optuna.org/)

---

## ğŸ“® Contact

è³ªå•ã‚„ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒã‚ã‚Œã°ã€GitHubã®Issuesã¾ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚
